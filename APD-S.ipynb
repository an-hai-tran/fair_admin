{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c77bf07f",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "030c858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# import libraries for machine learning models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# import libraries to solve LP\n",
    "from pulp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9258ce",
   "metadata": {},
   "source": [
    "# Output $p_i$ and $q_i$ for each candidate i $\\in$ [n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "1d2b3ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('clean_law_school.csv', index_col = 0)\n",
    "\n",
    "# split data into training and testing part\n",
    "target = ['admit', 'enroll']\n",
    "y = df[target]\n",
    "X = df.drop(target, axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, shuffle = True, random_state = 1)\n",
    "\n",
    "# implement the machine learning model to predict p_i and q_i\n",
    "lg_clf = ClassifierChain(RandomForestClassifier())\n",
    "lg_clf.fit(X_train, y_train)\n",
    "y_pred = lg_clf.predict_proba(X_test)\n",
    "X_test = pd.merge(X_test, y_test, left_index = True, right_index = True)\n",
    "X_test[['p_i', 'q_i']] = np.round(y_pred.toarray(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622475c5",
   "metadata": {},
   "source": [
    "# Generating input instance for APD-S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0313f8b9",
   "metadata": {},
   "source": [
    "In APD-S, since we assume there is only one academic unit (e.g, department) and one admission committe (AC), we would only select applicants from colleges with similar acceptance rate and admission rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c00b5f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    22754.000000\n",
       "mean         0.259164\n",
       "std          0.080609\n",
       "min          0.141930\n",
       "25%          0.206761\n",
       "50%          0.248110\n",
       "75%          0.287721\n",
       "max          0.479332\n",
       "Name: college_acceptance_rate, dtype: float64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary of college acceptance rate\n",
    "X_test['college_acceptance_rate'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1de21337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    22754.000000\n",
       "mean         0.074805\n",
       "std          0.039673\n",
       "min          0.015370\n",
       "25%          0.045344\n",
       "50%          0.062960\n",
       "75%          0.087537\n",
       "max          0.182125\n",
       "Name: college_admission_rate, dtype: float64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary of college admission rate\n",
    "X_test['college_admission_rate'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad3a04",
   "metadata": {},
   "source": [
    "Based on the summary of the statistics of acceptance and admission rate, we would select applicants who are in in the range of 25th percentile and 75th percentile only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8c37e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[(X_test['college_acceptance_rate'] >= np.percentile(X_test['college_acceptance_rate'], 25)) & \\\n",
    "                (X_test['college_acceptance_rate'] <= np.percentile(X_test['college_acceptance_rate'], 75)) & \\\n",
    "                (X_test['college_admission_rate'] >= np.percentile(X_test['college_admission_rate'], 25)) & \\\n",
    "                (X_test['college_admission_rate'] <= np.percentile(X_test['college_admission_rate'], 75))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171608f9",
   "metadata": {},
   "source": [
    "We generate the input instance as follow: create 10 random input instances from the testing data set, each with 1000 applicants.\n",
    "\n",
    "Note: we use the result of *admit* as *passing the interview* and *enroll* as *accepting the offer*.\n",
    "\n",
    "The input instance will have the following elements:\n",
    "- [n] = 1000 candidates\n",
    "- $p_i, q_i$ for each i $\\in$ [n]\n",
    "- In APD-S, we only have single interview-related constraint that can be captured as {g, B} with g = [n] being the only group in $G_I$. So $G_I$ contains only 1 group with n candidates.\n",
    "- We have enrollment-related budget constraints {g, $b_g|g \\in G_E$}. In this dataset, there are two groups inside $G_E$ which indicate candidates who are in-state and those who are out-of-state.\n",
    "- We capture the collection of protected groups of interest $G_P$ as the combination of the race and gender of the candidates. That means $G_P$ will have 8 groups by combining Race: {Black, Hispanic, Asian, White} and Gender: {Male, Female}.\n",
    "- For each candidate i $\\in g$ of $G_P, w_{ig}$ (the degree of relevance of i to g) is synthetically generated as random uniform number from [0,1]\n",
    "- We set the the cap on interview-related group g $B_g$ and enrollment-related group g $b_g$ using the actual statistics of the acceptance rate and admission rate from the dataset.\n",
    "- We are finding policies that define the target quota $\\tau_g$ for protected group g. However, the implementation of racial/gender quotas is not public or banned in some states. Alternatively we can follow the admission statistics of universities that apply Affirmative Action in their admission process. \n",
    "    + Specifically, we would use the statistics of Harvard Law School, known for its [yearly commitment to Affirmative Action in the admission/employment process](https://hr.harvard.edu/files/humanresources/files/reaffirmation_statement.pdf)\n",
    "    + Based on the [demographics of Hardvard Fall 2020 applications](https://www.ilrg.com/rankings/law/view/49), we set $\\tau_g$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a5585293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 5 random input instances from the testing data set, each with 1000 applicants\n",
    "n = 1000\n",
    "test_data = X_test.sample(n=n).reset_index(drop=True) # create 1 for testing purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9ce68a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsat</th>\n",
       "      <th>gpa</th>\n",
       "      <th>resident</th>\n",
       "      <th>gender</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>asian</th>\n",
       "      <th>white</th>\n",
       "      <th>other_race</th>\n",
       "      <th>college_acceptance_rate</th>\n",
       "      <th>college_admission_rate</th>\n",
       "      <th>admit</th>\n",
       "      <th>enroll</th>\n",
       "      <th>p_i</th>\n",
       "      <th>q_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158.0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215945</td>\n",
       "      <td>0.045344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.206761</td>\n",
       "      <td>0.086722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219449</td>\n",
       "      <td>0.053614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219449</td>\n",
       "      <td>0.053614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152.0</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285682</td>\n",
       "      <td>0.087537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>158.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248110</td>\n",
       "      <td>0.084958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>161.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285682</td>\n",
       "      <td>0.087537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>153.0</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.206761</td>\n",
       "      <td>0.086722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>154.0</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206827</td>\n",
       "      <td>0.066855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>160.0</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.215945</td>\n",
       "      <td>0.045344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lsat   gpa  resident  gender  black  hispanic  asian  white  other_race  \\\n",
       "0    158.0  3.62       0.0     1.0    0.0       0.0    0.0    1.0         0.0   \n",
       "1    137.0  2.85       0.0     0.0    0.0       0.0    0.0    0.0         1.0   \n",
       "2    154.0  3.44       1.0     0.0    0.0       0.0    0.0    1.0         0.0   \n",
       "3    165.0  3.95       0.0     1.0    0.0       0.0    0.0    1.0         0.0   \n",
       "4    152.0  3.21       0.0     1.0    0.0       0.0    0.0    0.0         1.0   \n",
       "..     ...   ...       ...     ...    ...       ...    ...    ...         ...   \n",
       "995  158.0  4.00       0.0     0.0    0.0       0.0    0.0    1.0         0.0   \n",
       "996  161.0  3.56       0.0     1.0    0.0       0.0    0.0    0.0         1.0   \n",
       "997  153.0  3.66       1.0     1.0    0.0       0.0    0.0    0.0         1.0   \n",
       "998  154.0  3.38       0.0     1.0    0.0       0.0    0.0    1.0         0.0   \n",
       "999  160.0  3.41       0.0     0.0    0.0       0.0    0.0    1.0         0.0   \n",
       "\n",
       "     college_acceptance_rate  college_admission_rate  admit  enroll    p_i  \\\n",
       "0                   0.215945                0.045344    0.0     0.0  0.000   \n",
       "1                   0.206761                0.086722    0.0     0.0  0.000   \n",
       "2                   0.219449                0.053614    0.0     0.0  0.010   \n",
       "3                   0.219449                0.053614    0.0     0.0  0.630   \n",
       "4                   0.285682                0.087537    0.0     0.0  0.020   \n",
       "..                       ...                     ...    ...     ...    ...   \n",
       "995                 0.248110                0.084958    0.0     0.0  0.132   \n",
       "996                 0.285682                0.087537    0.0     0.0  0.537   \n",
       "997                 0.206761                0.086722    0.0     0.0  0.422   \n",
       "998                 0.206827                0.066855    0.0     0.0  0.000   \n",
       "999                 0.215945                0.045344    0.0     0.0  0.000   \n",
       "\n",
       "      q_i  \n",
       "0    0.00  \n",
       "1    0.00  \n",
       "2    0.00  \n",
       "3    0.10  \n",
       "4    0.00  \n",
       "..    ...  \n",
       "995  0.00  \n",
       "996  0.02  \n",
       "997  0.00  \n",
       "998  0.00  \n",
       "999  0.00  \n",
       "\n",
       "[1000 rows x 15 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a1b68a2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_input(data):\n",
    "    # collection of interview-related groups\n",
    "    G_I = data\n",
    "    \n",
    "    # cap imposed on interview-related group g\n",
    "    B_g = len(data[data['admit'] == 1])\n",
    "    \n",
    "    # collection of enrollment-related groups\n",
    "    in_state = (data['resident'] == 1)\n",
    "    out_of_state = (data['resident'] == 0)\n",
    "    G_E = [data[in_state], data[out_of_state]]\n",
    "    \n",
    "    # cap imposed on enrollment-related group g\n",
    "    b_g = [len(data[in_state & (data['enroll'] == 1)]), len(data[out_of_state & (data['enroll'] == 1)])]\n",
    "    \n",
    "    # collection of protected groups\n",
    "    female_black = data[(data['gender'] == 0) & (data['black']==1)]\n",
    "    female_hispanic = data[(data['gender'] == 0) & (data['hispanic'] == 1)]\n",
    "    female_asian = data[(data['gender'] == 0) & (data['asian'] == 1)]\n",
    "    female_white = data[(data['gender'] == 0) & (data['white'] == 1)]\n",
    "    female_other = data[(data['gender'] == 0) & (data['other_race'] == 1)]\n",
    "    \n",
    "    male_black = data[(data['gender'] == 1) & (data['black'] == 1)]\n",
    "    male_hispanic = data[(data['gender'] == 1) & (data['hispanic'] == 1)]\n",
    "    male_asian = data[(data['gender'] == 1) & (data['asian'] == 1)]\n",
    "    male_white = data[(data['gender'] == 1) & (data['white'] == 1)]\n",
    "    male_other = data[(data['gender'] == 1) & (data['other_race'] == 1)]\n",
    "\n",
    "    G_P = [female_black, female_hispanic, female_asian, female_white, female_other,\\\n",
    "           male_black, male_hispanic, male_asian, male_white, male_other] \n",
    "    \n",
    "    # target quota for protected group g to achieve\n",
    "    tau_g = np.array([len(data)*0.0345, len(data)*0.0415, len(data)*0.0535, len(data)*0.252, len(data)*0.1185,\\\n",
    "             len(data)*0.0345, len(data)*0.0415, len(data)*0.0535, len(data)*0.252, len(data)*0.1185], int)\n",
    "    \n",
    "    # relevance of i to protected group g\n",
    "    w_ig = [np.random.uniform(size=len(g)) for g in G_P] #synthetic w_ig\n",
    "    \n",
    "    return G_I, G_E, G_P, B_g, b_g, tau_g, w_ig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b36a63",
   "metadata": {},
   "source": [
    "The objective model is max min$_{g \\in G_P} (\\sum_{i \\in g} w_{ig} y_i q_i / \\tau_g)$.\n",
    "\n",
    "We can rewrite it as the following to solve:\n",
    "\n",
    "max z\n",
    "\n",
    "s.t $ \\space \\space$  z $\\le \\sum_{i \\in g} w_{ig} y_i q_i / \\tau_g \\space \\space \\space \\space \\space \\space$ for $g \\in G_P$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "360b0906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def solveLP(data):\n",
    "    # create input instance\n",
    "    G_I, G_E, G_P, B_g, b_g, tau_g, w_ig = generate_input(data)\n",
    "    \n",
    "    # create model\n",
    "    model = LpProblem(name='APD-S', sense = LpMaximize)\n",
    "\n",
    "    # define decision variables\n",
    "    x_name = []\n",
    "    y_name = []\n",
    "    for i in range(n):\n",
    "        x_name.append('x' + str(i))\n",
    "        y_name.append('y' + str(i))\n",
    "\n",
    "    x = [LpVariable(x_name[i], lowBound = 0, upBound = 1) for i in range(n)]\n",
    "    y = [LpVariable(y_name[i], lowBound = 0, upBound = 1) for i in range(n)]\n",
    "    z = LpVariable(name='z')\n",
    "\n",
    "    # add objective function to the model\n",
    "    model += z\n",
    "\n",
    "    # constraints for z\n",
    "    for index_g in range(len(G_P)):\n",
    "        constraint = []\n",
    "        g = G_P[index_g]\n",
    "        for index_i in range(len(g)):\n",
    "            constraint.append(w_ig[index_g][index_i]*y[g.index[index_i]]*g.iloc[index_i]['q_i']/tau_g[index_g])\n",
    "        model += z <= lpSum(constraint)\n",
    "    \n",
    "    # constraints for (2) in LP\n",
    "    constraint = []\n",
    "    for index_g in range(len(G_I)):\n",
    "        constraint.append(x[index_g])\n",
    "    model += lpSum(constraint) <= B_g\n",
    "    \n",
    "    # constraints for (3) in LP\n",
    "    for i in range(n):\n",
    "        model += y[i] <= x[i]*data.iloc[i]['p_i']\n",
    "        \n",
    "    # constraints for (4) in LP\n",
    "    for index_g in range(len(G_E)):\n",
    "        constraint = []\n",
    "        g = G_E[index_g]\n",
    "        for index_i in range(len(g)):\n",
    "            constraint.append(y[g.index[index_i]]*g.iloc[index_i]['q_i'])\n",
    "        model += lpSum(constraint) <= b_g[index_g]\n",
    "    \n",
    "    # solve the model \n",
    "    model.solve()\n",
    "    \n",
    "    x_optimal = [0]*1000\n",
    "    y_optimal = [0]*1000\n",
    "\n",
    "    for var in model.variables()[:n]:\n",
    "        x_optimal[int(str(var.name)[1:])] = var.varValue\n",
    "    \n",
    "    for var in model.variables()[n:-1]:\n",
    "        y_optimal[int(str(var.name)[1:])] = var.varValue\n",
    "    \n",
    "    # return x*_i, y*_i for each candidate i\n",
    "    return model, x_optimal, y_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f63784b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /usr/local/lib/python3.8/dist-packages/pulp/apis/../solverdir/cbc/linux/64/cbc /tmp/4cc961cc2e534e15be3307233e3424f0-pulp.mps max timeMode elapsed branch printingOptions all solution /tmp/4cc961cc2e534e15be3307233e3424f0-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 1018 COLUMNS\n",
      "At line 4118 RHS\n",
      "At line 5132 BOUNDS\n",
      "At line 7134 ENDATA\n",
      "Problem MODEL has 1013 rows, 2001 columns and 3098 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Presolve 0 (-1013) rows, 0 (-2001) columns and 0 (-3098) elements\n",
      "Empty problem - 0 rows, 0 columns and 0 elements\n",
      "Optimal - objective value 0.00059490212\n",
      "After Postsolve, objective 0.00059490212, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Optimal objective 0.0005949021178 - 0 iterations time 0.002, Presolve 0.00\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, x, y = solveLP(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3cd940",
   "metadata": {},
   "source": [
    "Problem: x* is mostly in binary form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "48be4738",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constraint 2 is: True\n",
      "Constraint 3 is: True\n",
      "Constraint 4 is: True\n"
     ]
    }
   ],
   "source": [
    "# verify if x* and y* satisfy the constraints in the first batch of test data\n",
    "G_I, G_E, G_P, B_g, b_g, tau_g, w_ig = generate_input(test_data)\n",
    "\n",
    "# constraint 2\n",
    "print('Constraint 2 is:', sum(x) < B_g)\n",
    "\n",
    "# constraint 3\n",
    "flag = True\n",
    "for i in range(n):\n",
    "    if y[i] > x[i]*test_data.iloc[i]['p_i']:\n",
    "        flag = False\n",
    "print('Constraint 3 is:', flag)\n",
    "\n",
    "# constraint 4\n",
    "flag = True\n",
    "for index_g in range(len(G_E)):\n",
    "    g = G_E[index_g]\n",
    "    for index_i in range(len(g)):\n",
    "        if y[g.index[index_i]]*g.iloc[index_i]['q_i'] > b_g[index_g]:\n",
    "            flag = False\n",
    "print('Constraint 4 is:', flag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
