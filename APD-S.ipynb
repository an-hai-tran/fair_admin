{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c77bf07f",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "030c858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# import libraries for machine learning models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# import libraries to solve LP\n",
    "from pulp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9258ce",
   "metadata": {},
   "source": [
    "# Output $p_i$ and $q_i$ for each candidate i $\\in$ [n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d2b3ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('clean_law_school.csv', index_col = 0)\n",
    "\n",
    "# split data into training and testing part\n",
    "target = ['admit', 'enroll']\n",
    "y = df[target]\n",
    "X = df.drop(target, axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, shuffle = True, random_state = 1)\n",
    "\n",
    "# implement the machine learning model to predict p_i and q_i\n",
    "lg_clf = ClassifierChain(RandomForestClassifier(max_iter = 1000))\n",
    "lg_clf.fit(X_train, y_train)\n",
    "y_pred = lg_clf.predict_proba(X_test)\n",
    "X_test = pd.merge(X_test, y_test, left_index = True, right_index = True)\n",
    "X_test[['p_i', 'q_i']] = y_pred.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622475c5",
   "metadata": {},
   "source": [
    "# Generating input instance for APD-S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171608f9",
   "metadata": {},
   "source": [
    "We generate the input as follow:\n",
    "- [n] = 1000 candidates\n",
    "- $p_i, q_i$ for each i in the testing dataset\n",
    "- In APD-S, we only have single interview-related constraint that can be captured as {g, B} with g = [n] being the only group in $G_I$. So $G_I$ contains 1 group only with n candidates.\n",
    "- We have enrollment-related budget constraints {g, $b_g|g \\in G_E$}. There are two groups inside $G_E$ imply candidates who are in-state and those who are out-of-state. '\n",
    "- We generate the collection of protected groups of interest $G_P$ as the combination of the race and gender of the candidates. That means $G_P$ will have 8 groups by combining Race: {Black, Hispanic, Asian, White} and Gender: {Male, Female}.\n",
    "- For each candidate i $\\in g$ of G_P, w_ig (the degree of relevance of i to g) is synthetically generated as random uniform number from [0,1]\n",
    "- We set the the cap on interview-relagted and enrollment-related groups using the actual statistics of the admittance and enrollment from the dataset. The range of acceptance rate is 14 to 30% and admission rate is 2 to 10%.\n",
    "- We are finding policies that define the target quota $\\tau_g$ for protected group g. However, the implementation of racial/gender quotas is not public or banned in some states. Alternatively we can follow the admission statistics of universities that apply Affirmative Action in their admission process. \n",
    "    + Specifically, we would use the statistics of Harvard Law School, known for its [yearly commitment to Affirmative Action in the admission/employment process](https://hr.harvard.edu/files/humanresources/files/reaffirmation_statement.pdf)\n",
    "    + Based on the [admission statistics of Hardvard J.D. Class of 2024](https://hls.harvard.edu/dept/jdadmissions/apply-to-harvard-law-school/hls-profile-and-facts/), we set $\\tau_g$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5585293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 10 random input instances from the testing data set, each with 1000 applicants\n",
    "n = 1000\n",
    "test_data = [X_test.sample(n=n).reset_index(drop=True) for num in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b68a2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_input(data):\n",
    "    # collection of interview-related groups\n",
    "    G_I = data\n",
    "    \n",
    "    # cap imposed on interview-related group g\n",
    "    B_g = len(G_I)*0.4\n",
    "    \n",
    "    # collection of enrollment-related groups\n",
    "    in_state = (data['resident'] == 1) & (data['enroll'] == 1)\n",
    "    out_of_state = (data['resident'] == 0) & (data['enroll'] == 1)\n",
    "    G_E = [data[in_state], data[out_of_state]]\n",
    "    \n",
    "    # cap imposed on enrollment-related group g\n",
    "    b_g = [len(G_E[num]) for num in range(len(G_E))]\n",
    "    \n",
    "    # collection of protected groups\n",
    "    female_black = (data['gender'] == 0) & (data['black']==1)\n",
    "    female_hispanic = (data['gender'] == 0) & (data['hispanic'] == 1)\n",
    "    female_asian = (data['gender'] == 0) & (data['asian'] == 1)\n",
    "    female_white = (data['gender'] == 0) & (data['white'] == 1)\n",
    "    \n",
    "    male_black = (data['gender'] == 1) & (data['black'] == 1)\n",
    "    male_hispanic = (data['gender'] == 1) & (data['hispanic'] == 1)\n",
    "    male_asian = (data['gender'] == 1) & (data['asian'] == 1)\n",
    "    male_white = (data['gender'] == 1) & (data['white'] == 1)\n",
    "\n",
    "    G_P = [data[female_black], data[female_hispanic], data[female_asian], data[female_white],\\\n",
    "           data[male_black], data[male_hispanic], data[male_asian], data[male_white]] \n",
    "    \n",
    "    # target quota for protected group g to achieve\n",
    "    tau_g = [len(data[female_black & (data['enroll'] == 1)]) + 1, len(data[female_hispanic & (data['enroll'] == 1)]) + 1,\\\n",
    "             len(data[female_asian & (data['enroll'] == 1)]) + 1, len(data[female_white & (data['enroll'] == 1)]) + 1,\\\n",
    "             len(data[male_black & (data['enroll'] == 1)]) + 1, len(data[male_hispanic & (data['enroll'] == 1)]) + 1,\\\n",
    "             len(data[male_asian & (data['enroll'] == 1)]) + 1, len(data[male_white & (data['enroll'] == 1)]) + 1]\n",
    "    \n",
    "    # relevance of i to protected group g\n",
    "    w_ig = [np.random.uniform(size=len(g)) for g in G_P] #synthetic w_ig\n",
    "    \n",
    "    return G_I, G_E, G_P, B_g, b_g, tau_g, w_ig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b36a63",
   "metadata": {},
   "source": [
    "The objective model is max min$_{g \\in G_P} (\\sum_{i \\in g} w_{ig} y_i q_i / \\tau_g)$.\n",
    "\n",
    "We can rewrite it as the following to solve:\n",
    "\n",
    "max z\n",
    "\n",
    "s.t $ \\space \\space$  z $\\le \\sum_{i \\in g} w_{ig} y_i q_i / \\tau_g \\space \\space \\space \\space \\space \\space \\forall  g \\in G_P$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "360b0906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def solveLP(data):\n",
    "    # create input instance\n",
    "    G_I, G_E, G_P, B_g, b_g, tau_g, w_ig = generate_input(data)\n",
    "    \n",
    "    # create model\n",
    "    model = LpProblem(name='APD-S', sense=LpMaximize)\n",
    "\n",
    "    # define decision variables\n",
    "    x_name = []\n",
    "    y_name = []\n",
    "    for i in range(n):\n",
    "        x_name.append('x' + str(i))\n",
    "        y_name.append('y' + str(i))\n",
    "\n",
    "    x = [LpVariable(x_name[i], lowBound = 0, upBound = 1) for i in range(n)]\n",
    "    y = [LpVariable(y_name[i], lowBound = 0, upBound = 1) for i in range(n)]\n",
    "    z = LpVariable(name='z')\n",
    "\n",
    "    # add objective function to the model\n",
    "    model += LpAffineExpression(z)\n",
    "\n",
    "    # constraints for z\n",
    "    for index_g in range(len(G_P)):\n",
    "        constraint = []\n",
    "        g = G_P[index_g]\n",
    "        for index_i in range(len(g)):\n",
    "            constraint.append(w_ig[index_g][index_i]*y[g.index[index_i]]*g.iloc[index_i]['q_i']/tau_g[index_g])\n",
    "        model += z <= lpSum(constraint)\n",
    "    \n",
    "    # constraints for (2) in LP\n",
    "    constraint = []\n",
    "    for index_g in range(len(G_I)):\n",
    "        constraint.append(x[index_g])\n",
    "    model += lpSum(constraint) <= B_g\n",
    "    \n",
    "    # constraints for (3) in LP\n",
    "    for i in range(n):\n",
    "        model += y[i] <= x[i]*data.iloc[i]['p_i']\n",
    "        \n",
    "    # constraints for (4) in LP\n",
    "    for index_g in range(len(G_E)):\n",
    "        constraint = []\n",
    "        g = G_E[index_g]\n",
    "        for index_i in range(len(g)):\n",
    "            constraint.append(y[g.index[index_i]]*g.iloc[index_i]['q_i'])\n",
    "        model += lpSum(constraint) <= b_g[index_g]\n",
    "    \n",
    "    # solve the model \n",
    "    model.solve()\n",
    "    \n",
    "    # return x*_i, y*_i for each candidate i\n",
    "    return [var.varValue for var in model.variables()[:n]], [var.varValue for var in model.variables()[n:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4951a81b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /usr/local/lib/python3.8/dist-packages/pulp/apis/../solverdir/cbc/linux/64/cbc /tmp/23e08ae06a6e4cdfbd18ba5b48ae8ce8-pulp.mps max timeMode elapsed branch printingOptions all solution /tmp/23e08ae06a6e4cdfbd18ba5b48ae8ce8-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 1016 COLUMNS\n",
      "At line 5104 RHS\n",
      "At line 6116 BOUNDS\n",
      "At line 8118 ENDATA\n",
      "Problem MODEL has 1011 rows, 2001 columns and 4086 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Presolve 1009 (-2) rows, 2001 (0) columns and 4008 (-78) elements\n",
      "Perturbing problem by 0.001% of 0.0066848091 - largest nonzero change 0 ( 0%) - largest zero change 4.9969769e-05\n",
      "0  Obj 0.18153773 Primal inf 709.95683 (8)\n",
      "95  Obj 0.11030571 Primal inf 379.52237 (584)\n",
      "171  Obj 0.11022189 Primal inf 384.24996 (595)\n",
      "266  Obj 0.10764168 Primal inf 336.08117 (558)\n",
      "361  Obj 0.10198097 Primal inf 281.34443 (490)\n",
      "456  Obj 0.095286692 Primal inf 225.09323 (402)\n",
      "551  Obj 0.090399424 Primal inf 178.10676 (337)\n",
      "646  Obj 0.086968855 Primal inf 138.08806 (272)\n",
      "741  Obj 0.083486258 Primal inf 83.406036 (190)\n",
      "836  Obj 0.081848492 Primal inf 94.861674 (159)\n",
      "931  Obj 0.075743445 Primal inf 57.326693 (166)\n",
      "1026  Obj 0.072268721 Primal inf 17.917812 (73)\n",
      "1096  Obj 0.071430522\n",
      "1096  Obj 0.073376817 Dual inf 9.0737087e-05 (6)\n",
      "1104  Obj 0.073377939\n",
      "Optimal - objective value 0.073377939\n",
      "After Postsolve, objective 0.073377939, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Optimal objective 0.07337793866 - 1104 iterations time 0.012, Presolve 0.00\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.02   (Wallclock seconds):       0.03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_optimal, y_optimal = solveLP(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3cd940",
   "metadata": {},
   "source": [
    "Problem: x* is mostly in binary form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48be4738",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constraint 2 is: False\n",
      "Constraint 3 is: False\n",
      "Constraint 4 is: False\n"
     ]
    }
   ],
   "source": [
    "# verify if x* and y* satisfy the constraints in the first batch of test data\n",
    "G_I, G_E, G_P, B_g, b_g, tau_g, w_ig = generate_input(test_data[0])\n",
    "\n",
    "# constraint 2\n",
    "print('Constraint 2 is:', sum(x_optimal) < B_g)\n",
    "# print('Sum of x*_i:', sum(x_optimal))\n",
    "# print('Cap B_g:', B_g)\n",
    "\n",
    "# constraint 3\n",
    "flag = True\n",
    "for i in range(n):\n",
    "    if y_optimal[i] > x_optimal[i]*test_data[0].iloc[i]['p_i']:\n",
    "        flag = False\n",
    "#       print('y*' + str(i) + ':', y_optimal[i])\n",
    "#       print('x*' + str(i) + '.' + 'p' + str(i) + ':', x_optimal[i]*test_data[0].iloc[i]['p_i'])\n",
    "print('Constraint 3 is:', flag)\n",
    "\n",
    "# constraint 4\n",
    "flag = True\n",
    "for index_g in range(len(G_E)):\n",
    "    g = G_E[index_g]\n",
    "    for index_i in range(len(g)):\n",
    "        if y_optimal[g.index[index_i]]*g.iloc[index_i]['q_i'] <= b_g[index_g]:\n",
    "            flag = False\n",
    "print('Constraint 4 is:', flag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
