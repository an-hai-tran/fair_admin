{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c77bf07f",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "030c858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# import libraries for machine learning models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# import libraries to solve LP\n",
    "from pulp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9258ce",
   "metadata": {},
   "source": [
    "# Output $p_i$ and $q_i$ for each candidate i $\\in$ [n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d2b3ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('clean_law_school.csv', index_col = 0)\n",
    "\n",
    "# split data into training and testing part\n",
    "target = ['admit', 'enroll']\n",
    "y = df[target]\n",
    "X = df.drop(target, axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, shuffle = True, random_state = 1)\n",
    "\n",
    "# implement the machine learning model to predict p_i and q_i\n",
    "lg_clf = ClassifierChain(RandomForestClassifier())\n",
    "lg_clf.fit(X_train, y_train)\n",
    "y_pred = lg_clf.predict_proba(X_test)\n",
    "X_test = pd.merge(X_test, y_test, left_index = True, right_index = True)\n",
    "X_test[['p_i', 'q_i']] = np.round(y_pred.toarray(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622475c5",
   "metadata": {},
   "source": [
    "# Generating input instance for APD-S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1595a085",
   "metadata": {},
   "source": [
    "In APD-S, since we assume there is only one academic unit (e.g, department) and one admission committe (AC), we would only select applicants from colleges with similar acceptance rate and admission rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7db0594a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    22754.000000\n",
       "mean         0.259164\n",
       "std          0.080609\n",
       "min          0.141930\n",
       "25%          0.206761\n",
       "50%          0.248110\n",
       "75%          0.287721\n",
       "max          0.479332\n",
       "Name: college_acceptance_rate, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary of college acceptance rate\n",
    "X_test['college_acceptance_rate'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bfc8bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    22754.000000\n",
       "mean         0.074805\n",
       "std          0.039673\n",
       "min          0.015370\n",
       "25%          0.045344\n",
       "50%          0.062960\n",
       "75%          0.087537\n",
       "max          0.182125\n",
       "Name: college_admission_rate, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary of college admission rate\n",
    "X_test['college_admission_rate'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c6337",
   "metadata": {},
   "source": [
    "Based on the summary of the statistics of acceptance and admission rate, we would select applicants who are in in the range of 25th percentile and 75th percentile only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2a38a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[(X_test['college_acceptance_rate'] >= np.percentile(X_test['college_acceptance_rate'], 25)) & \\\n",
    "                (X_test['college_acceptance_rate'] <= np.percentile(X_test['college_acceptance_rate'], 75)) & \\\n",
    "                (X_test['college_admission_rate'] >= np.percentile(X_test['college_admission_rate'], 25)) & \\\n",
    "                (X_test['college_admission_rate'] <= np.percentile(X_test['college_admission_rate'], 75))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171608f9",
   "metadata": {},
   "source": [
    "We generate the input instance as follow: create 10 random input instances from the testing data set, each with 1000 applicants.\n",
    "\n",
    "Note: we use the result of *admit* as *passing the interview* and *enroll* as *accepting the offer*.\n",
    "\n",
    "The input instance will have the following elements:\n",
    "- [n] = 1000 candidates\n",
    "- $p_i, q_i$ for each i $\\in$ [n]\n",
    "- In APD-S, we only have single interview-related constraint that can be captured as {g, B} with g = [n] being the only group in $G_I$. So $G_I$ contains only 1 group with n candidates.\n",
    "- We have enrollment-related budget constraints {g, $b_g|g \\in G_E$}. In this dataset, there are two groups inside $G_E$ which indicate candidates who are in-state and those who are out-of-state.\n",
    "- We capture the collection of protected groups of interest $G_P$ as the combination of the race and gender of the candidates. That means $G_P$ will have 8 groups by combining Race: {Black, Hispanic, Asian, White} and Gender: {Male, Female}.\n",
    "- For each candidate i $\\in g$ of $G_P, w_{ig}$ (the degree of relevance of i to g) is calculated by check if the candidate has the same race and gender as the protected group\n",
    "- We set the the cap on interview-related group g $B_g$ and enrollment-related group g $b_g$ using the actual statistics of the acceptance rate and admission rate from the dataset.\n",
    "- We are finding policies that define the target quota $\\tau_g$ for protected group g. However, the implementation of racial/gender quotas is not public or banned in some states. Alternatively we can follow the admission statistics of universities that apply Affirmative Action in their admission process. \n",
    "    + Specifically, we would use the statistics of Harvard Law School, known for its [yearly commitment to Affirmative Action in the admission/employment process](https://hr.harvard.edu/files/humanresources/files/reaffirmation_statement.pdf)\n",
    "    + Based on the [demographics of Hardvard Fall 2020 applications](https://www.ilrg.com/rankings/law/view/49), we calculate the percentage of each protected group in the enrollment number and set $\\tau_g$ accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37428c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 10 random input instances from the testing data set, each with 1000 applicants\n",
    "n = 1000\n",
    "test_data = [X_test.sample(n=n).reset_index(drop=True) for num in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1b68a2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_input(data):\n",
    "    # collection of interview-related groups\n",
    "    G_I = data\n",
    "    \n",
    "    # cap imposed on interview-related group g\n",
    "    B_g = len(data[data['admit'] == 1])\n",
    "    \n",
    "    # collection of enrollment-related groups\n",
    "    in_state = (data['resident'] == 1)\n",
    "    out_of_state = (data['resident'] == 0)\n",
    "    G_E = [data[in_state], data[out_of_state]]\n",
    "    \n",
    "    # cap imposed on enrollment-related group g\n",
    "    b_g = [len(data[in_state & (data['enroll'] == 1)]), len(data[out_of_state & (data['enroll'] == 1)])]\n",
    "    \n",
    "    # collection of protected groups\n",
    "    female_black = data[(data['gender'] == 0) & (data['black']==1)]\n",
    "    female_hispanic = data[(data['gender'] == 0) & (data['hispanic'] == 1)]\n",
    "    female_asian = data[(data['gender'] == 0) & (data['asian'] == 1)]\n",
    "    female_white = data[(data['gender'] == 0) & (data['white'] == 1)]\n",
    "    female_other = data[(data['gender'] == 0) & (data['other_race'] == 1)]\n",
    "    \n",
    "    male_black = data[(data['gender'] == 1) & (data['black'] == 1)]\n",
    "    male_hispanic = data[(data['gender'] == 1) & (data['hispanic'] == 1)]\n",
    "    male_asian = data[(data['gender'] == 1) & (data['asian'] == 1)]\n",
    "    male_white = data[(data['gender'] == 1) & (data['white'] == 1)]\n",
    "    male_other = data[(data['gender'] == 1) & (data['other_race'] == 1)]\n",
    "\n",
    "    G_P = [female_black, female_hispanic, female_asian, female_white, female_other,\\\n",
    "           male_black, male_hispanic, male_asian, male_white, male_other] \n",
    "    \n",
    "    # target quota for protected group g to achieve\n",
    "    tau_g = np.array([len(data)*0.0345, len(data)*0.0415, len(data)*0.0535, len(data)*0.252, len(data)*0.1185,\\\n",
    "             len(data)*0.0345, len(data)*0.0415, len(data)*0.0535, len(data)*0.252, len(data)*0.1185], int)\n",
    "    \n",
    "    # relevance of i to protected group g\n",
    "    w_ig = [np.random.uniform(size=len(g)) for g in G_P] #synthetic w_ig\n",
    "    \n",
    "    return G_I, G_E, G_P, B_g, b_g, tau_g, w_ig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b36a63",
   "metadata": {},
   "source": [
    "The objective model is max min$_{g \\in G_P} (\\sum_{i \\in g} w_{ig} y_i q_i / \\tau_g)$.\n",
    "\n",
    "We can rewrite it as the following to solve:\n",
    "\n",
    "max z\n",
    "\n",
    "s.t $ \\space \\space$  z $\\le \\sum_{i \\in g} w_{ig} y_i q_i / \\tau_g \\space \\space \\space \\space \\space \\space$ for $g \\in G_P$\n",
    "\n",
    "Other constraints will be kept as original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "360b0906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def solveLP(data):\n",
    "    # create input instance\n",
    "    G_I, G_E, G_P, B_g, b_g, tau_g, w_ig = generate_input(data)\n",
    "    \n",
    "    # create model\n",
    "    model = LpProblem(name='APD-S', sense = LpMaximize)\n",
    "\n",
    "    # define decision variables\n",
    "    x_name = []\n",
    "    y_name = []\n",
    "    for i in range(n):\n",
    "        x_name.append('x' + str(i))\n",
    "        y_name.append('y' + str(i))\n",
    "\n",
    "    x = [LpVariable(x_name[i], lowBound = 0, upBound = 1) for i in range(n)]\n",
    "    y = [LpVariable(y_name[i], lowBound = 0, upBound = 1) for i in range(n)]\n",
    "    z = LpVariable(name='z')\n",
    "\n",
    "    # add objective function to the model\n",
    "    model += z\n",
    "\n",
    "    # constraints for z\n",
    "    for index_g in range(len(G_P)):\n",
    "        constraint = []\n",
    "        g = G_P[index_g]\n",
    "        for index_i in range(len(g)):\n",
    "            constraint.append(w_ig[index_g][index_i]*y[g.index[index_i]]*g.iloc[index_i]['q_i']/tau_g[index_g])\n",
    "        model += z <= lpSum(constraint)\n",
    "    \n",
    "    # constraints for (2) in LP\n",
    "    constraint = []\n",
    "    for index_g in range(len(G_I)):\n",
    "        constraint.append(x[index_g])\n",
    "    model += lpSum(constraint) <= B_g\n",
    "    \n",
    "    # constraints for (3) in LP\n",
    "    for i in range(n):\n",
    "        model += y[i] <= x[i]*data.iloc[i]['p_i']\n",
    "        \n",
    "    # constraints for (4) in LP\n",
    "    for index_g in range(len(G_E)):\n",
    "        constraint = []\n",
    "        g = G_E[index_g]\n",
    "        for index_i in range(len(g)):\n",
    "            constraint.append(y[g.index[index_i]]*g.iloc[index_i]['q_i'])\n",
    "        model += lpSum(constraint) <= b_g[index_g]\n",
    "    \n",
    "    # solve the model \n",
    "    model.solve(PULP_CBC_CMD(msg=0))\n",
    "    print('-> The solution is', LpStatus[model.status])\n",
    "    \n",
    "    x_optimal = [0]*n\n",
    "    y_optimal = [0]*n\n",
    "\n",
    "    for var in model.variables()[:n]:\n",
    "        x_optimal[int(str(var.name)[1:])] = round(var.varValue, 3)\n",
    "    \n",
    "    for var in model.variables()[n:-1]:\n",
    "        y_optimal[int(str(var.name)[1:])] = round(var.varValue, 3)\n",
    "    \n",
    "    # return x*_i, y*_i for each candidate i\n",
    "    return x_optimal, y_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48be4738",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying input instance number 0\n",
      "-> The solution is Optimal\n",
      "-> Every constraints has been satisfied \n",
      "\n",
      "Verifying input instance number 1\n",
      "-> The solution is Optimal\n",
      "-> Every constraints has been satisfied \n",
      "\n",
      "Verifying input instance number 2\n",
      "-> The solution is Optimal\n",
      "-> Every constraints has been satisfied \n",
      "\n",
      "Verifying input instance number 3\n",
      "-> The solution is Optimal\n",
      "-> Every constraints has been satisfied \n",
      "\n",
      "Verifying input instance number 4\n",
      "-> The solution is Optimal\n",
      "-> Every constraints has been satisfied \n",
      "\n",
      "Verifying input instance number 5\n",
      "-> The solution is Optimal\n",
      "-> Every constraints has been satisfied \n",
      "\n",
      "Verifying input instance number 6\n",
      "-> The solution is Optimal\n",
      "-> Every constraints has been satisfied \n",
      "\n",
      "Verifying input instance number 7\n",
      "-> The solution is Optimal\n",
      "-> Every constraints has been satisfied \n",
      "\n",
      "Verifying input instance number 8\n",
      "-> The solution is Optimal\n",
      "-> Every constraints has been satisfied \n",
      "\n",
      "Verifying input instance number 9\n",
      "-> The solution is Optimal\n",
      "-> Every constraints has been satisfied \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# verify if x* and y* of each input instance satisfy the constraints \n",
    "x_optimal = []\n",
    "y_optimal = []\n",
    "for index in range(len(test_data)):\n",
    "    print('Verifying input instance number', index)\n",
    "    x, y = solveLP(test_data[index])\n",
    "    x_optimal.append(x)\n",
    "    y_optimal.append(y)\n",
    "\n",
    "    G_I, G_E, G_P, B_g, b_g, tau_g, w_ig = generate_input(test_data[index])\n",
    "    flag = True\n",
    "    \n",
    "    # constraint 2\n",
    "    if sum(x_optimal[index]) > B_g:\n",
    "        flag = False\n",
    "\n",
    "    # constraint 3\n",
    "    for i in range(n):\n",
    "        if y_optimal[index][i] > x_optimal[index][i]*test_data[index].iloc[i]['p_i']:\n",
    "            flag = False\n",
    "    \n",
    "    # constraint 4\n",
    "    for index_g in range(len(G_E)):\n",
    "        g = G_E[index_g]\n",
    "        for index_i in range(len(g)):\n",
    "            if y_optimal[index][g.index[index_i]]*g.iloc[index_i]['q_i'] > b_g[index_g]:\n",
    "                flag = False\n",
    "    \n",
    "    if flag:\n",
    "        print('-> Every constraints has been satisfied \\n')\n",
    "    else:\n",
    "        print('-> Not every constraints has been satisfied \\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
